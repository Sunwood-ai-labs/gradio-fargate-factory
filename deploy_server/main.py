from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import subprocess
import boto3
from loguru import logger
import os
from dotenv import load_dotenv

load_dotenv()

logger.add("deploy_server.log", rotation="1 MB")
app = FastAPI()

AWS_REGION = "ap-northeast-1"
CLUSTER_NAME = "gradio-ecs-cluster"

class DeployRequest(BaseModel):
    app_name: str
    docker_context: str = "./"  # Dockerfileã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    dockerfile: str = "Dockerfile"  # Dockerfileåï¼ˆçœç•¥å¯ï¼‰
    alb_path: str  # ä¾‹: "/image-filter/*"
    git_repo_url: str | None = None  # è¿½åŠ : ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹Gitãƒªãƒã‚¸ãƒˆãƒªURLï¼ˆçœç•¥å¯ï¼‰
    # æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
    cpu: str = "2048"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤§å¹…ã«å¢—åŠ 
    memory: str = "4096"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤§å¹…ã«å¢—åŠ 
    force_recreate: bool = False  # å¼·åˆ¶å†ä½œæˆãƒ•ãƒ©ã‚°

@app.post("/deploy")
def deploy_app(req: DeployRequest):
    import tempfile
    import shutil

    app_name = req.app_name
    docker_context = req.docker_context
    dockerfile = req.dockerfile

    temp_dir = None
    deployed_url = None
    
    # git_repo_urlãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã‚¯ãƒ­ãƒ¼ãƒ³
    if req.git_repo_url:
        import datetime
        tmp_base = os.getenv("CLONE_BASE_DIR", "/home/cc-company/gradio-fargate-factory/tmp")
        tmp_base = os.path.abspath(tmp_base)
        os.makedirs(tmp_base, exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        temp_dir = os.path.join(tmp_base, f"{app_name}_{timestamp}")
        try:
            subprocess.check_call([
                "git", "clone", req.git_repo_url, temp_dir
            ])
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Git clone failed: {e}")
        docker_context = temp_dir

    try:
        # AWSæƒ…å ±å–å¾—
        sts = boto3.client("sts", region_name=AWS_REGION)
        account_id = sts.get_caller_identity()["Account"]
        ecr = boto3.client("ecr", region_name=AWS_REGION)
        ecs = boto3.client("ecs", region_name=AWS_REGION)
        elbv2 = boto3.client("elbv2", region_name=AWS_REGION)
        logs = boto3.client("logs", region_name=AWS_REGION)

        # ECRãƒªãƒã‚¸ãƒˆãƒªURLå–å¾—ï¼ˆãªã‘ã‚Œã°ä½œæˆï¼‰
        try:
            ecr_url = ecr.describe_repositories(repositoryNames=[app_name])["repositories"][0]["repositoryUri"]
        except ecr.exceptions.RepositoryNotFoundException:
            repo = ecr.create_repository(repositoryName=app_name)
            ecr_url = repo["repository"]["repositoryUri"]

        # Dockerãƒ­ã‚°ã‚¤ãƒ³
        login_pw = subprocess.check_output([
            "aws", "ecr", "get-login-password", "--region", AWS_REGION
        ]).decode().strip()
        login_cmd = [
            "docker", "login",
            "--username", "AWS",
            "--password-stdin",
            f"{account_id}.dkr.ecr.{AWS_REGION}.amazonaws.com"
        ]
        proc = subprocess.Popen(login_cmd, stdin=subprocess.PIPE)
        proc.communicate(input=login_pw.encode())
        if proc.returncode != 0:
            raise Exception("Docker login failed")

        # Dockerãƒ“ãƒ«ãƒ‰ï¼†ãƒ—ãƒƒã‚·ãƒ¥
        import traceback
        try:
            result = subprocess.run(
                [
                    "docker", "build", "--platform", "linux/amd64", "-t", f"{app_name}:latest", "-f", dockerfile, "."
                ],
                capture_output=True,
                text=True,
                cwd=docker_context
            )
            if result.returncode != 0:
                err_msg = (
                    f"docker build failed (exit code {result.returncode})\n"
                    f"stdout:\n{result.stdout}\n"
                    f"stderr:\n{result.stderr}\n"
                    f"{traceback.format_exc()}"
                )
                raise HTTPException(status_code=500, detail=err_msg)
        except Exception as e:
            err_msg = f"docker build exception: {e}\n{traceback.format_exc()}"
            raise HTTPException(status_code=500, detail=err_msg)
        subprocess.check_call([
            "docker", "tag", f"{app_name}:latest", f"{ecr_url}:latest"
        ])
        subprocess.check_call([
            "docker", "push", f"{ecr_url}:latest"
        ])

        # ALBãƒªã‚¹ãƒŠãƒ¼ãƒ«ãƒ¼ãƒ«è¿½åŠ 
        alb_listener_arn = os.environ.get("ALB_LISTENER_ARN")
        if not alb_listener_arn:
            raise Exception("ALB_LISTENER_ARNç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™")
        alb_path = req.alb_path

        # ALBã®VPCæƒ…å ±ã‚’å–å¾—
        listener_info = elbv2.describe_listeners(ListenerArns=[alb_listener_arn])
        lb_arn = listener_info["Listeners"][0]["LoadBalancerArn"]
        
        # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        lb_info = elbv2.describe_load_balancers(LoadBalancerArns=[lb_arn])
        alb_vpc_id = lb_info["LoadBalancers"][0]["VpcId"]
        alb_dns_name = lb_info["LoadBalancers"][0]["DNSName"]
        
        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æ±ºå®š
        protocol = "http"
        try:
            listeners = elbv2.describe_listeners(LoadBalancerArn=lb_arn)["Listeners"]
            has_https = any(listener["Port"] == 443 for listener in listeners)
            if has_https:
                protocol = "https"
        except Exception:
            protocol = "http"
        
        # ### <<< ä¿®æ­£ >>> ###
        # ãƒ‡ãƒ—ãƒ­ã‚¤URLã¨Gradioã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ‘ã‚¹ã‚’ã“ã“ã§ä¸€å…ƒçš„ã«å®šç¾©
        base_path = alb_path.rstrip("/*").rstrip("/")  # "/myapp/*" -> "/myapp"
        deployed_url = f"{protocol}://{alb_dns_name}{base_path}"
        gradio_root_path = base_path # Gradioã‚¢ãƒ—ãƒªã«æ¸¡ã™ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        health_check_path = "/" # Gradioã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ãƒ‘ã‚¹
        # health_check_path = "/health-check"
        
        logger.info(f"ALB DNS Name: {alb_dns_name}")
        logger.info(f"Target URL: {deployed_url}")
        logger.info(f"Gradio Root Path will be set to: {gradio_root_path}")
        logger.info(f"Target Group Health Check Path will be set to: {health_check_path}")


        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã®ç¢ºèªãƒ»ä½œæˆãƒ»æ›´æ–°
        tg_name = f"{app_name}-tg"
        tg_arn = None
        
        try:
            existing_tgs = elbv2.describe_target_groups(Names=[tg_name])["TargetGroups"]
            tg_arn = existing_tgs[0]["TargetGroupArn"]
            logger.info(f"Using existing target group: {tg_name}")
            # ### <<< è¿½åŠ  >>> ###
            # æ—¢å­˜ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è¨­å®šã‚’æ›´æ–°
            elbv2.modify_target_group(
                TargetGroupArn=tg_arn,
                HealthCheckPath=health_check_path,
                HealthCheckIntervalSeconds=30, # é–“éš”ã‚’çŸ­ãã—ã¦æ—©æœŸå¾©æ—§
                HealthCheckTimeoutSeconds=15, # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚‚èª¿æ•´
                HealthyThresholdCount=2,
                UnhealthyThresholdCount=3, # å¤±æ•—å›æ•°ã‚’æ¸›ã‚‰ã—ã¦æ—©ãåˆ‡ã‚Šé›¢ã™
                Matcher={'HttpCode': '200'} # Gradioã®/health-checkã¯200ã‚’è¿”ã™
            )
            logger.info(f"Updated health check path for target group '{tg_name}' to '{health_check_path}'")

        except elbv2.exceptions.TargetGroupNotFoundException:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ–°è¦ä½œæˆ
            logger.info(f"Creating new target group: {tg_name}")
            # ### <<< ä¿®æ­£ >>> ###
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ‘ã‚¹ã‚’æ­£ã—ãè¨­å®š
            tg = elbv2.create_target_group(
                Name=tg_name,
                Protocol="HTTP",
                Port=7860,
                VpcId=alb_vpc_id,
                TargetType="ip",
                HealthCheckPath=health_check_path, # æ­£ã—ã„ãƒ‘ã‚¹ã‚’è¨­å®š
                HealthCheckProtocol="HTTP",
                HealthCheckIntervalSeconds=30,
                HealthCheckTimeoutSeconds=15,
                HealthyThresholdCount=2,
                UnhealthyThresholdCount=3,
                Matcher={'HttpCode': '200'} # 200ã®ã¿ã‚’æ­£å¸¸ã¨ã¿ãªã™
            )
            tg_arn = tg["TargetGroups"][0]["TargetGroupArn"]
            logger.info(f"Created target group: {tg_name}")

        # ALBãƒ«ãƒ¼ãƒ«ã®ç¢ºèªãƒ»ä½œæˆ
        rules = elbv2.describe_rules(ListenerArn=alb_listener_arn)["Rules"]
        rule_exists = False
        for rule in rules:
            for cond in rule.get("Conditions", []):
                if cond.get("Field") == "path-pattern" and alb_path in cond.get("Values", []):
                    rule_exists = True
                    # ### <<< è¿½åŠ  >>> ###
                    # ãƒ«ãƒ¼ãƒ«ãŒæ—¢ã«ã‚ã‚Œã°ã€è»¢é€å…ˆTGãŒæ­£ã—ã„ã‹ç¢ºèªãƒ»ä¿®æ­£ã™ã‚‹
                    is_correct_tg = False
                    for action in rule.get("Actions", []):
                        if action.get("TargetGroupArn") == tg_arn:
                            is_correct_tg = True
                            break
                    if not is_correct_tg:
                        logger.warning(f"Rule for path '{alb_path}' exists but points to wrong TG. Modifying...")
                        elbv2.modify_rule(
                            RuleArn=rule['RuleArn'],
                            Actions=[{'Type': 'forward', 'TargetGroupArn': tg_arn}]
                        )
                    break
            if rule_exists:
                break
        
        if not rule_exists:
            existing_priorities = [int(rule.get("Priority", 0)) for rule in rules if rule.get("Priority") != "default"]
            next_priority = max(existing_priorities) + 1 if existing_priorities else 100
            
            elbv2.create_rule(
                ListenerArn=alb_listener_arn,
                Priority=next_priority,
                Conditions=[{"Field": "path-pattern", "Values": [alb_path]}],
                Actions=[{"Type": "forward", "TargetGroupArn": tg_arn}]
            )
            logger.info(f"Created ALB rule with priority {next_priority}")

        # ECSã‚¿ã‚¹ã‚¯å®šç¾©ã®è¨­å®š
        task_definition_family = app_name # ã‚¿ã‚¹ã‚¯å®šç¾©ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚¢ãƒ—ãƒªåã¨ä¸€è‡´ã•ã›ã‚‹
        execution_role_arn = os.environ.get("ECS_TASK_EXECUTION_ROLE_ARN")
        task_role_arn = os.environ.get("ECS_TASK_ROLE_ARN")
        
        if not execution_role_arn or not task_role_arn:
            raise HTTPException(status_code=500, detail="ECS role ARNs not configured")

        # CloudWatch Logsã®ç¢ºèª
        log_group_name = f"/ecs/{app_name}"
        try:
            logs.create_log_group(logGroupName=log_group_name)
            logger.info(f"Created log group: {log_group_name}")
        except logs.exceptions.ResourceAlreadyExistsException:
            logger.info(f"Log group already exists: {log_group_name}")

        # æ–°ã—ã„ã‚¿ã‚¹ã‚¯å®šç¾©ã‚’ç™»éŒ²
        logger.info(f"Registering task definition with CPU: {req.cpu}, Memory: {req.memory}")
        ecs.register_task_definition(
            family=task_definition_family,
            networkMode="awsvpc",
            requiresCompatibilities=["FARGATE"],
            cpu=req.cpu,
            memory=req.memory,
            executionRoleArn=execution_role_arn,
            taskRoleArn=task_role_arn,
            containerDefinitions=[
                {
                    "name": app_name,
                    "image": f"{ecr_url}:latest",
                    "portMappings": [
                        {
                            "containerPort": 7860,
                            "protocol": "tcp"
                        }
                    ],
                    "essential": True,
                    # ### <<< ä¿®æ­£ >>> ###
                    # ç’°å¢ƒå¤‰æ•°ã«GRADIO_ROOT_PATHã‚’è¿½åŠ 
                    "environment": [
                        {"name": "GRADIO_SERVER_NAME", "value": "0.0.0.0"},
                        {"name": "GRADIO_SERVER_PORT", "value": "7860"},
                        {"name": "GRADIO_ROOT_PATH", "value": gradio_root_path}
                    ],
                    "logConfiguration": {
                        "logDriver": "awslogs",
                        "options": {
                            "awslogs-group": log_group_name,
                            "awslogs-region": AWS_REGION,
                            "awslogs-stream-prefix": "ecs"
                        }
                    }
                }
            ]
        )

        # ã‚µãƒ–ãƒãƒƒãƒˆè¨­å®š
        subnets_env = os.environ.get("SUBNETS") or os.environ.get("PUBLIC_SUBNET_IDS") or os.environ.get("PRIVATE_SUBNET_IDS") or ""
        subnets = [s.strip() for s in subnets_env.split(",") if s.strip()]
        security_groups = [s.strip() for s in os.environ.get("SECURITY_GROUPS", "").split(",") if s.strip()]

        # ECSã‚µãƒ¼ãƒ“ã‚¹ã®å‡¦ç†
        services = ecs.describe_services(cluster=CLUSTER_NAME, services=[app_name])["services"]
        
        if services and services[0]["status"] == "ACTIVE" and not req.force_recreate:
            # æ—¢å­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ›´æ–°
            logger.info(f"Updating existing ECS service: {app_name}")
            try:
                ecs.update_service(
                    cluster=CLUSTER_NAME,
                    service=app_name,
                    taskDefinition=task_definition_family, # ### <<< ä¿®æ­£ >>> ### familyåã‚’æ¸¡ã™
                    enableExecuteCommand=True, 
                    forceNewDeployment=True
                )
                logger.info(f"Successfully updated service: {app_name}")
                deployment_type = "update"
                
            except Exception as update_e:
                logger.error(f"Failed to update service: {update_e}")
                raise HTTPException(status_code=500, detail=f"Service update failed: {update_e}")
                
        else:
            # æ–°ã—ã„ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œæˆ
            if services and req.force_recreate:
                logger.info(f"Force recreate requested - deleting existing service")
                try:
                    ecs.delete_service(cluster=CLUSTER_NAME, service=app_name, force=True)
                    logger.info(f"Deleted existing service for recreation")
                    
                    # å‰Šé™¤å®Œäº†ã‚’å¾…æ©Ÿ
                    import time
                    for i in range(30):
                        time.sleep(10)
                        try:
                            remaining = ecs.describe_services(cluster=CLUSTER_NAME, services=[app_name])["services"]
                            if not remaining or remaining[0]["status"] == "INACTIVE":
                                logger.info(f"Service deletion completed after {(i+1)*10} seconds")
                                break
                        except:
                            break
                except Exception as del_e:
                    logger.warning(f"Failed to delete service: {del_e}")
            
            logger.info(f"Creating new ECS service: {app_name}")
            try:
                ecs.create_service(
                    cluster=CLUSTER_NAME,
                    serviceName=app_name,
                    taskDefinition=task_definition_family, # ### <<< ä¿®æ­£ >>> ### familyåã‚’æ¸¡ã™
                    enableExecuteCommand=True,
                    loadBalancers=[{
                        "targetGroupArn": tg_arn,
                        "containerName": app_name,
                        "containerPort": 7860
                    }],
                    desiredCount=1,
                    launchType="FARGATE",
                    networkConfiguration={
                        "awsvpcConfiguration": {
                            "subnets": subnets,
                            "securityGroups": security_groups,
                            "assignPublicIp": "ENABLED" # é–‹ç™ºãƒ»æ¤œè¨¼ç”¨é€”ã¨ã—ã¦ENABLEDã®ã¾ã¾
                        }
                    },
                    healthCheckGracePeriodSeconds=300 # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®çŒ¶äºˆæœŸé–“
                )
                logger.info(f"Successfully created service: {app_name}")
                deployment_type = "create"
                
            except Exception as create_e:
                logger.error(f"Failed to create service: {create_e}")
                raise HTTPException(status_code=500, detail=f"Service creation failed: {create_e}")

        # æˆåŠŸãƒ­ã‚°ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        logger.info(f"ğŸš€ Deployment completed: {deployed_url}")
        logger.info(f"ğŸ’¾ Resources: CPU={req.cpu}, Memory={req.memory}")
        logger.info(f"â±ï¸  Allow 5-10 minutes for service to become healthy")
        
        return {
            "status": "success",
            "message": f"{app_name} deployed successfully!",
            "deployed_url": deployed_url,
            "alb_dns_name": alb_dns_name,
            "alb_path": alb_path,
            "app_name": app_name,
            "protocol": protocol,
            "cpu": req.cpu,
            "memory": req.memory,
            "deployment_type": deployment_type,
            "estimated_ready_time": "5-10 minutes"
        }
        
    except Exception as e:
        logger.error(f"Deployment failed: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"Cleaned up: {temp_dir}")
            except Exception as cleanup_e:
                logger.warning(f"Cleanup failed: {cleanup_e}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
